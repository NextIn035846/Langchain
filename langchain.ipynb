{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add secret key openai\n",
    "os.environ['OPEN_API_KEY']=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature Value --> how creative we want our model to be.\n",
    "\n",
    "0 --> temperature it means model is very safe it is not taking any bets.\n",
    "\n",
    "1 --> it will take risk it might generate wrong output but it is very creative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=os.environ['OPEN_API_KEY'] ,temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of india\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:\\LangChain\\langchain\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "llm_hugging =HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0.7,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output= llm_hugging.predict(\"Can you write a poem about AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the way i look at the world i love the way i feel i love the way i think i feel i love the way i feel i love the way i think i feel i love the way i feel i love the way \n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nAI is here to help us find our way \\nTo make decisions, diagnosis, and more each day \\nIt can sometimes be seen as a saving grace \\nBut it’s not too far from taking over the place \\n\\nIt can be seen as a blessing or a curse \\nIt can be used to help us or make our lives worse \\nAI can be the gift we could never have dreamed of \\nBut it could also be the thing that takes us away from love \\n\\nIt’s a technology that’s both powerful and scary \\nIt could make us more efficient or make us less wary \\nBut no matter what, AI will always be here \\nSo let’s use it wisely and show it some care.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Can you write a poem about AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates And Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this India'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'],\n",
    "template = \"Tell me the capital of this {country}\")\n",
    "prompt_template.format(country =\"India\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of India is New Delhi.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm,prompt=prompt_template)\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining multiple chain using simple Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'],template=\"Please tell me the capital of the {country}\")\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables=['capital'],template='Suggest me some amazing place to visit in {capital}')\n",
    "famous_chai = LLMChain(llm=llm,prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" There are many amazing places to visit in and around the city. Some of the most popular places to visit in New Delhi are:\\n\\n1. India Gate\\n2. Red Fort\\n3. Jama Masjid\\n4. Lotus Temple\\n5. Qutub Minar\\n6. Humayun's Tomb\\n7. Akshardham Temple\\n8. Chandni Chowk\\n9. Jantar Mantar\\n10. Rashtrapati Bhavan\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chai])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'],template=\"Please tell me the capital of the {country}\")\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_prompt,output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables=['capital'],template='Suggest me some amazing place to visit in {capital}')\n",
    "famous_chai = LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[capital_chain,famous_chai],input_variables=['country'],output_variables=['capital','places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'places': \" Some amazing places to visit in New Delhi are:\\n\\n1. Red Fort: A UNESCO World Heritage Site, the majestic Red Fort is a must-visit in Delhi. \\n\\n2. India Gate: This memorial commemorates the soldiers who lost their lives fighting for the country.\\n\\n3. Qutub Minar: This UNESCO World Heritage Site is a towering minaret, standing at a height of 73 metres.\\n\\n4. Humayun's Tomb: This stunning structure is a UNESCO World Heritage Site and is a must-visit for history buffs.\\n\\n5. Lotus Temple: This stunning temple is a Baháʼí House of Worship and is a must-visit for tourists.\\n\\n6. Akshardham Temple: This sprawling temple complex is one of the most visited places in Delhi.\\n\\n7. Jama Masjid: This stunning mosque is one of the largest in India and is a must-visit for tourists.\\n\\n8. Chandni Chowk: This bustling market is a great place to shop for traditional Indian wares.\\n\\n9. Rashtrapati Bhavan: This grand building is the official residence of the President of India and is a must-visit.\\n\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "chain({'country':'India'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
    "chat_llm = ChatOpenAI(openai_api_key=os.environ['OPEN_API_KEY'] ,temperature=0.7,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the AI go to therapy? Because it had too many unresolved issues with Siri-ous jealousy!')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm(\n",
    "[\n",
    "    SystemMessage(content='Your are a comedian AI assitant'),\n",
    "    HumanMessage(content=\"Please provide some comedy punchline on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template LLM Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant . When the user given any input, you should generate 5 words synonym in a comma separated list\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chat_llm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' knowledgeable', ' quick-witted', ' sharp']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
